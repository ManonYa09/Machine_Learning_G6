{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169135b0-662c-47e3-a813-919dd6158bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, pandas as pd, seaborn as sns, numpy as np, matplotlib.pyplot as plt\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6f4ee8-cf85-4b09-bc98-fad238245e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Normalization, Dense, InputLayer\n",
    "from tensorflow.keras.losses import MeanSquaredError, Huber, MeanAbsoluteError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718d4d2d-516a-48ee-af6b-7fa2b51fe821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ManonYa09/Machine-_Learning_G4/refs/heads/main/Dataset/4.%20WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a759e13c-385d-4812-a494-d751a20023e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/0019w3h141s2b0z27906x13c0000gn/T/ipykernel_62038/2767291496.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Churn'] = df['Churn'].replace({'Yes':1, 'No':0})\n"
     ]
    }
   ],
   "source": [
    "df['Churn'] = df['Churn'].replace({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edb368e2-f10c-47f8-abec-2d92bf1b2aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "\n",
       "      PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0  Electronic check          29.85         29.85     0  \n",
       "1      Mailed check          56.95        1889.5     0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e60bcbb-620b-4dca-8a39-533a5d8cf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc936ba0-2aba-4bc1-9dad-a9e01d3d1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "numerical_columns = []\n",
    "target = 'Churn'\n",
    "excluded_columns = ['customerID', 'TotalCharges', 'gender']\n",
    "\n",
    "for column in df.columns:\n",
    "    if column in excluded_columns + [target]:\n",
    "        continue\n",
    "    unique_values = df[column].nunique()\n",
    "    if unique_values <= 4:\n",
    "        categorical_columns.append(column)\n",
    "    else:\n",
    "        numerical_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a74eaee-42c7-47eb-acb3-43c2c8d9198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(X):\n",
    "    return X.drop(columns=excluded_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f52d651-9322-4d73-9e92-3d29c61471a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('Scaling', StandardScaler(), numerical_columns),\n",
    "    ('Ecoding', OneHotEncoder(), categorical_columns),\n",
    "])\n",
    "pipepline = Pipeline([\n",
    "    ('drop', FunctionTransformer(drop_columns)),\n",
    "    ('prepro', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102ad087-c61a-484f-8ac6-754fb1b00982",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=target)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02569240-7690-4f3c-ae00-d9ba356189d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = pipepline.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40727b7e-bd52-4a4b-98f8-8dd49ea3f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "771fa9c9-6be5-4d81-95e3-9e54219dc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a4fdd8-5338-4204-a1d7-04e06631fa17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "63d886e0-c81b-4789-9a19-5191cbbfcc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "  # Determine input shape dynamically\n",
    "model = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(input_shape,)),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5d74afa7-6226-4b26-8832-39eb751bb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d3e0dd50-5348-48b1-9c15-62a8a8d1707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.8134 - loss: 0.3982 - val_accuracy: 0.8098 - val_loss: 0.4080\n",
      "Epoch 2/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.8124 - loss: 0.3919 - val_accuracy: 0.8041 - val_loss: 0.4134\n",
      "Epoch 3/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.8209 - loss: 0.3743 - val_accuracy: 0.7835 - val_loss: 0.4386\n",
      "Epoch 4/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.8109 - loss: 0.3956 - val_accuracy: 0.8070 - val_loss: 0.4184\n",
      "Epoch 5/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.8084 - loss: 0.3955 - val_accuracy: 0.8020 - val_loss: 0.4170\n",
      "Epoch 6/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.8030 - loss: 0.4010 - val_accuracy: 0.8020 - val_loss: 0.4179\n",
      "Epoch 7/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8181 - loss: 0.3826 - val_accuracy: 0.8041 - val_loss: 0.4246\n",
      "Epoch 8/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.8235 - loss: 0.3731 - val_accuracy: 0.8048 - val_loss: 0.4261\n",
      "Epoch 9/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.8267 - loss: 0.3778 - val_accuracy: 0.8034 - val_loss: 0.4258\n",
      "Epoch 10/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.8198 - loss: 0.3836 - val_accuracy: 0.8034 - val_loss: 0.4254\n",
      "Epoch 11/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.8273 - loss: 0.3723 - val_accuracy: 0.8048 - val_loss: 0.4284\n",
      "Epoch 12/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.8249 - loss: 0.3754 - val_accuracy: 0.7999 - val_loss: 0.4355\n",
      "Epoch 13/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.8255 - loss: 0.3613 - val_accuracy: 0.7864 - val_loss: 0.4448\n",
      "Epoch 14/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.8291 - loss: 0.3606 - val_accuracy: 0.7970 - val_loss: 0.4489\n",
      "Epoch 15/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.8137 - loss: 0.3818 - val_accuracy: 0.7949 - val_loss: 0.4369\n",
      "Epoch 16/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8343 - loss: 0.3602 - val_accuracy: 0.7928 - val_loss: 0.4463\n",
      "Epoch 17/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.8246 - loss: 0.3701 - val_accuracy: 0.7984 - val_loss: 0.4537\n",
      "Epoch 18/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.8372 - loss: 0.3520 - val_accuracy: 0.7899 - val_loss: 0.4421\n",
      "Epoch 19/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.8293 - loss: 0.3483 - val_accuracy: 0.7928 - val_loss: 0.4501\n",
      "Epoch 20/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.8434 - loss: 0.3474 - val_accuracy: 0.7977 - val_loss: 0.4576\n",
      "Epoch 21/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.8273 - loss: 0.3612 - val_accuracy: 0.7928 - val_loss: 0.4486\n",
      "Epoch 22/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.8281 - loss: 0.3566 - val_accuracy: 0.7814 - val_loss: 0.4644\n",
      "Epoch 23/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.8380 - loss: 0.3536 - val_accuracy: 0.7913 - val_loss: 0.4582\n",
      "Epoch 24/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8436 - loss: 0.3360 - val_accuracy: 0.7857 - val_loss: 0.4678\n",
      "Epoch 25/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.8432 - loss: 0.3380 - val_accuracy: 0.7864 - val_loss: 0.4561\n",
      "Epoch 26/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.8496 - loss: 0.3291 - val_accuracy: 0.7871 - val_loss: 0.4696\n",
      "Epoch 27/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.8442 - loss: 0.3374 - val_accuracy: 0.7807 - val_loss: 0.4668\n",
      "Epoch 28/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8368 - loss: 0.3408 - val_accuracy: 0.7899 - val_loss: 0.4654\n",
      "Epoch 29/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.8419 - loss: 0.3279 - val_accuracy: 0.7899 - val_loss: 0.4928\n",
      "Epoch 30/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.8485 - loss: 0.3224 - val_accuracy: 0.7757 - val_loss: 0.4870\n",
      "Epoch 31/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.8497 - loss: 0.3257 - val_accuracy: 0.7828 - val_loss: 0.4792\n",
      "Epoch 32/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.8532 - loss: 0.3209 - val_accuracy: 0.7750 - val_loss: 0.4894\n",
      "Epoch 33/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8521 - loss: 0.3218 - val_accuracy: 0.7842 - val_loss: 0.4804\n",
      "Epoch 34/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.8585 - loss: 0.3156 - val_accuracy: 0.7892 - val_loss: 0.5088\n",
      "Epoch 35/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.8477 - loss: 0.3212 - val_accuracy: 0.7708 - val_loss: 0.4961\n",
      "Epoch 36/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.8479 - loss: 0.3236 - val_accuracy: 0.7722 - val_loss: 0.5012\n",
      "Epoch 37/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.8571 - loss: 0.3077 - val_accuracy: 0.7750 - val_loss: 0.5041\n",
      "Epoch 38/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.8581 - loss: 0.3006 - val_accuracy: 0.7750 - val_loss: 0.4993\n",
      "Epoch 39/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.8596 - loss: 0.3042 - val_accuracy: 0.7786 - val_loss: 0.5102\n",
      "Epoch 40/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.8495 - loss: 0.3141 - val_accuracy: 0.7786 - val_loss: 0.5072\n",
      "Epoch 41/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.8590 - loss: 0.2993 - val_accuracy: 0.7842 - val_loss: 0.5092\n",
      "Epoch 42/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.8656 - loss: 0.2960 - val_accuracy: 0.7693 - val_loss: 0.5174\n",
      "Epoch 43/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.8610 - loss: 0.3002 - val_accuracy: 0.7736 - val_loss: 0.5160\n",
      "Epoch 44/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.8648 - loss: 0.2933 - val_accuracy: 0.7828 - val_loss: 0.5218\n",
      "Epoch 45/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8752 - loss: 0.2745 - val_accuracy: 0.7779 - val_loss: 0.5350\n",
      "Epoch 46/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.8561 - loss: 0.3032 - val_accuracy: 0.7750 - val_loss: 0.5362\n",
      "Epoch 47/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.8657 - loss: 0.2886 - val_accuracy: 0.7771 - val_loss: 0.5299\n",
      "Epoch 48/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.8721 - loss: 0.2799 - val_accuracy: 0.7771 - val_loss: 0.5448\n",
      "Epoch 49/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.8723 - loss: 0.2801 - val_accuracy: 0.7779 - val_loss: 0.5458\n",
      "Epoch 50/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.8793 - loss: 0.2769 - val_accuracy: 0.7764 - val_loss: 0.5569\n",
      "Epoch 51/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.8723 - loss: 0.2766 - val_accuracy: 0.7764 - val_loss: 0.5411\n",
      "Epoch 52/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.8846 - loss: 0.2678 - val_accuracy: 0.7743 - val_loss: 0.5513\n",
      "Epoch 53/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8743 - loss: 0.2799 - val_accuracy: 0.7743 - val_loss: 0.5581\n",
      "Epoch 54/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.8751 - loss: 0.2779 - val_accuracy: 0.7665 - val_loss: 0.5701\n",
      "Epoch 55/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.8743 - loss: 0.2718 - val_accuracy: 0.7786 - val_loss: 0.5666\n",
      "Epoch 56/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8807 - loss: 0.2619 - val_accuracy: 0.7630 - val_loss: 0.5761\n",
      "Epoch 57/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.8607 - loss: 0.2867 - val_accuracy: 0.7644 - val_loss: 0.5773\n",
      "Epoch 58/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8890 - loss: 0.2565 - val_accuracy: 0.7771 - val_loss: 0.5780\n",
      "Epoch 59/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.8808 - loss: 0.2709 - val_accuracy: 0.7750 - val_loss: 0.5791\n",
      "Epoch 60/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.8870 - loss: 0.2512 - val_accuracy: 0.7637 - val_loss: 0.5797\n",
      "Epoch 61/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.8881 - loss: 0.2535 - val_accuracy: 0.7679 - val_loss: 0.5807\n",
      "Epoch 62/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.8874 - loss: 0.2536 - val_accuracy: 0.7644 - val_loss: 0.5906\n",
      "Epoch 63/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.8829 - loss: 0.2628 - val_accuracy: 0.7679 - val_loss: 0.5895\n",
      "Epoch 64/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.8865 - loss: 0.2570 - val_accuracy: 0.7715 - val_loss: 0.5867\n",
      "Epoch 65/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.8879 - loss: 0.2592 - val_accuracy: 0.7594 - val_loss: 0.6112\n",
      "Epoch 66/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8885 - loss: 0.2595 - val_accuracy: 0.7665 - val_loss: 0.6082\n",
      "Epoch 67/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.8917 - loss: 0.2445 - val_accuracy: 0.7708 - val_loss: 0.6021\n",
      "Epoch 68/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.8892 - loss: 0.2493 - val_accuracy: 0.7587 - val_loss: 0.6245\n",
      "Epoch 69/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.8986 - loss: 0.2382 - val_accuracy: 0.7587 - val_loss: 0.6269\n",
      "Epoch 70/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.8955 - loss: 0.2449 - val_accuracy: 0.7665 - val_loss: 0.6234\n",
      "Epoch 71/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.8915 - loss: 0.2419 - val_accuracy: 0.7551 - val_loss: 0.6299\n",
      "Epoch 72/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.8881 - loss: 0.2454 - val_accuracy: 0.7764 - val_loss: 0.6281\n",
      "Epoch 73/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8998 - loss: 0.2310 - val_accuracy: 0.7693 - val_loss: 0.6354\n",
      "Epoch 74/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.8944 - loss: 0.2408 - val_accuracy: 0.7658 - val_loss: 0.6312\n",
      "Epoch 75/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.8921 - loss: 0.2386 - val_accuracy: 0.7729 - val_loss: 0.6225\n",
      "Epoch 76/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8967 - loss: 0.2296 - val_accuracy: 0.7665 - val_loss: 0.6531\n",
      "Epoch 77/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.9023 - loss: 0.2247 - val_accuracy: 0.7686 - val_loss: 0.6538\n",
      "Epoch 78/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.8948 - loss: 0.2339 - val_accuracy: 0.7693 - val_loss: 0.6566\n",
      "Epoch 79/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8978 - loss: 0.2300 - val_accuracy: 0.7658 - val_loss: 0.6739\n",
      "Epoch 80/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8927 - loss: 0.2399 - val_accuracy: 0.7622 - val_loss: 0.6532\n",
      "Epoch 81/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8991 - loss: 0.2317 - val_accuracy: 0.7608 - val_loss: 0.6830\n",
      "Epoch 82/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.8916 - loss: 0.2339 - val_accuracy: 0.7764 - val_loss: 0.6735\n",
      "Epoch 83/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9011 - loss: 0.2226 - val_accuracy: 0.7559 - val_loss: 0.6701\n",
      "Epoch 84/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9089 - loss: 0.2199 - val_accuracy: 0.7651 - val_loss: 0.6711\n",
      "Epoch 85/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.8940 - loss: 0.2324 - val_accuracy: 0.7573 - val_loss: 0.6792\n",
      "Epoch 86/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.9046 - loss: 0.2200 - val_accuracy: 0.7622 - val_loss: 0.6771\n",
      "Epoch 87/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.9041 - loss: 0.2209 - val_accuracy: 0.7488 - val_loss: 0.7077\n",
      "Epoch 88/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.8976 - loss: 0.2231 - val_accuracy: 0.7665 - val_loss: 0.7013\n",
      "Epoch 89/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.8926 - loss: 0.2339 - val_accuracy: 0.7594 - val_loss: 0.7175\n",
      "Epoch 90/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9143 - loss: 0.2111 - val_accuracy: 0.7729 - val_loss: 0.6833\n",
      "Epoch 91/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9072 - loss: 0.2157 - val_accuracy: 0.7630 - val_loss: 0.6963\n",
      "Epoch 92/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9091 - loss: 0.2133 - val_accuracy: 0.7587 - val_loss: 0.7078\n",
      "Epoch 93/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9116 - loss: 0.2042 - val_accuracy: 0.7594 - val_loss: 0.7206\n",
      "Epoch 94/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9081 - loss: 0.2113 - val_accuracy: 0.7686 - val_loss: 0.7147\n",
      "Epoch 95/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.9103 - loss: 0.2053 - val_accuracy: 0.7693 - val_loss: 0.7356\n",
      "Epoch 96/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.9026 - loss: 0.2222 - val_accuracy: 0.7559 - val_loss: 0.7304\n",
      "Epoch 97/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.9047 - loss: 0.2167 - val_accuracy: 0.7509 - val_loss: 0.7419\n",
      "Epoch 98/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9098 - loss: 0.2085 - val_accuracy: 0.7637 - val_loss: 0.7414\n",
      "Epoch 99/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9084 - loss: 0.2116 - val_accuracy: 0.7566 - val_loss: 0.7365\n",
      "Epoch 100/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.9053 - loss: 0.2056 - val_accuracy: 0.7438 - val_loss: 0.7635\n",
      "Epoch 101/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.9040 - loss: 0.2200 - val_accuracy: 0.7466 - val_loss: 0.7508\n",
      "Epoch 102/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9008 - loss: 0.2253 - val_accuracy: 0.7637 - val_loss: 0.7612\n",
      "Epoch 103/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.8999 - loss: 0.2200 - val_accuracy: 0.7651 - val_loss: 0.7583\n",
      "Epoch 104/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9051 - loss: 0.2113 - val_accuracy: 0.7530 - val_loss: 0.7626\n",
      "Epoch 105/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9124 - loss: 0.2033 - val_accuracy: 0.7431 - val_loss: 0.7770\n",
      "Epoch 106/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.9166 - loss: 0.2023 - val_accuracy: 0.7594 - val_loss: 0.7742\n",
      "Epoch 107/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9140 - loss: 0.1954 - val_accuracy: 0.7630 - val_loss: 0.7697\n",
      "Epoch 108/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.9009 - loss: 0.2197 - val_accuracy: 0.7665 - val_loss: 0.7556\n",
      "Epoch 109/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.9078 - loss: 0.2004 - val_accuracy: 0.7615 - val_loss: 0.7763\n",
      "Epoch 110/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9192 - loss: 0.1892 - val_accuracy: 0.7459 - val_loss: 0.7930\n",
      "Epoch 111/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.9190 - loss: 0.1902 - val_accuracy: 0.7637 - val_loss: 0.7831\n",
      "Epoch 112/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9021 - loss: 0.2165 - val_accuracy: 0.7601 - val_loss: 0.7796\n",
      "Epoch 113/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.9099 - loss: 0.2053 - val_accuracy: 0.7573 - val_loss: 0.7999\n",
      "Epoch 114/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9122 - loss: 0.1981 - val_accuracy: 0.7544 - val_loss: 0.8154\n",
      "Epoch 115/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9091 - loss: 0.2033 - val_accuracy: 0.7466 - val_loss: 0.8176\n",
      "Epoch 116/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.9077 - loss: 0.2088 - val_accuracy: 0.7544 - val_loss: 0.8067\n",
      "Epoch 117/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9115 - loss: 0.1989 - val_accuracy: 0.7672 - val_loss: 0.8007\n",
      "Epoch 118/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.9124 - loss: 0.1955 - val_accuracy: 0.7544 - val_loss: 0.8272\n",
      "Epoch 119/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9126 - loss: 0.1912 - val_accuracy: 0.7488 - val_loss: 0.8053\n",
      "Epoch 120/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.9092 - loss: 0.1958 - val_accuracy: 0.7622 - val_loss: 0.8336\n",
      "Epoch 121/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.9136 - loss: 0.1949 - val_accuracy: 0.7601 - val_loss: 0.8036\n",
      "Epoch 122/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9084 - loss: 0.2057 - val_accuracy: 0.7708 - val_loss: 0.8102\n",
      "Epoch 123/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.9108 - loss: 0.1917 - val_accuracy: 0.7708 - val_loss: 0.8399\n",
      "Epoch 124/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9223 - loss: 0.1847 - val_accuracy: 0.7658 - val_loss: 0.8486\n",
      "Epoch 125/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9102 - loss: 0.1953 - val_accuracy: 0.7608 - val_loss: 0.8568\n",
      "Epoch 126/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.9120 - loss: 0.2004 - val_accuracy: 0.7729 - val_loss: 0.8466\n",
      "Epoch 127/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.9119 - loss: 0.1957 - val_accuracy: 0.7580 - val_loss: 0.8606\n",
      "Epoch 128/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9148 - loss: 0.1920 - val_accuracy: 0.7601 - val_loss: 0.8581\n",
      "Epoch 129/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.9002 - loss: 0.2030 - val_accuracy: 0.7473 - val_loss: 0.8671\n",
      "Epoch 130/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9156 - loss: 0.1898 - val_accuracy: 0.7466 - val_loss: 0.8787\n",
      "Epoch 131/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.9094 - loss: 0.1874 - val_accuracy: 0.7686 - val_loss: 0.8581\n",
      "Epoch 132/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.9028 - loss: 0.2020 - val_accuracy: 0.7551 - val_loss: 0.8790\n",
      "Epoch 133/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9204 - loss: 0.1830 - val_accuracy: 0.7573 - val_loss: 0.8623\n",
      "Epoch 134/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.9234 - loss: 0.1804 - val_accuracy: 0.7637 - val_loss: 0.8889\n",
      "Epoch 135/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9141 - loss: 0.1881 - val_accuracy: 0.7658 - val_loss: 0.8826\n",
      "Epoch 136/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.9136 - loss: 0.1948 - val_accuracy: 0.7410 - val_loss: 0.9042\n",
      "Epoch 137/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.9175 - loss: 0.1849 - val_accuracy: 0.7573 - val_loss: 0.9304\n",
      "Epoch 138/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9161 - loss: 0.1868 - val_accuracy: 0.7551 - val_loss: 0.8957\n",
      "Epoch 139/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9207 - loss: 0.1760 - val_accuracy: 0.7665 - val_loss: 0.8979\n",
      "Epoch 140/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9210 - loss: 0.1765 - val_accuracy: 0.7516 - val_loss: 0.9171\n",
      "Epoch 141/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.9179 - loss: 0.1829 - val_accuracy: 0.7622 - val_loss: 0.9231\n",
      "Epoch 142/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.9146 - loss: 0.1881 - val_accuracy: 0.7580 - val_loss: 0.9123\n",
      "Epoch 143/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9234 - loss: 0.1752 - val_accuracy: 0.7608 - val_loss: 0.9101\n",
      "Epoch 144/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.9276 - loss: 0.1684 - val_accuracy: 0.7637 - val_loss: 0.8774\n",
      "Epoch 145/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.9178 - loss: 0.1796 - val_accuracy: 0.7644 - val_loss: 0.9216\n",
      "Epoch 146/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9276 - loss: 0.1686 - val_accuracy: 0.7665 - val_loss: 0.9476\n",
      "Epoch 147/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9162 - loss: 0.1875 - val_accuracy: 0.7608 - val_loss: 0.9231\n",
      "Epoch 148/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9155 - loss: 0.1782 - val_accuracy: 0.7601 - val_loss: 0.9398\n",
      "Epoch 149/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.9175 - loss: 0.1758 - val_accuracy: 0.7544 - val_loss: 0.9422\n",
      "Epoch 150/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9256 - loss: 0.1725 - val_accuracy: 0.7608 - val_loss: 0.9727\n",
      "Epoch 151/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9234 - loss: 0.1745 - val_accuracy: 0.7559 - val_loss: 0.9407\n",
      "Epoch 152/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.9199 - loss: 0.1773 - val_accuracy: 0.7452 - val_loss: 0.9564\n",
      "Epoch 153/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9129 - loss: 0.1921 - val_accuracy: 0.7459 - val_loss: 0.9652\n",
      "Epoch 154/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9212 - loss: 0.1769 - val_accuracy: 0.7544 - val_loss: 0.9521\n",
      "Epoch 155/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9201 - loss: 0.1740 - val_accuracy: 0.7644 - val_loss: 0.9576\n",
      "Epoch 156/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9186 - loss: 0.1816 - val_accuracy: 0.7459 - val_loss: 0.9570\n",
      "Epoch 157/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.9151 - loss: 0.1809 - val_accuracy: 0.7559 - val_loss: 0.9654\n",
      "Epoch 158/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9275 - loss: 0.1683 - val_accuracy: 0.7452 - val_loss: 0.9594\n",
      "Epoch 159/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.9157 - loss: 0.1895 - val_accuracy: 0.7544 - val_loss: 0.9662\n",
      "Epoch 160/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9287 - loss: 0.1685 - val_accuracy: 0.7530 - val_loss: 0.9638\n",
      "Epoch 161/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9277 - loss: 0.1695 - val_accuracy: 0.7488 - val_loss: 0.9769\n",
      "Epoch 162/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.9274 - loss: 0.1677 - val_accuracy: 0.7566 - val_loss: 0.9774\n",
      "Epoch 163/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9280 - loss: 0.1648 - val_accuracy: 0.7459 - val_loss: 0.9855\n",
      "Epoch 164/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9214 - loss: 0.1759 - val_accuracy: 0.7651 - val_loss: 0.9732\n",
      "Epoch 165/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9203 - loss: 0.1740 - val_accuracy: 0.7459 - val_loss: 0.9771\n",
      "Epoch 166/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9175 - loss: 0.1793 - val_accuracy: 0.7530 - val_loss: 0.9678\n",
      "Epoch 167/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9225 - loss: 0.1685 - val_accuracy: 0.7495 - val_loss: 1.0024\n",
      "Epoch 168/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.9252 - loss: 0.1693 - val_accuracy: 0.7587 - val_loss: 1.0003\n",
      "Epoch 169/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9291 - loss: 0.1621 - val_accuracy: 0.7530 - val_loss: 1.0559\n",
      "Epoch 170/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9170 - loss: 0.1798 - val_accuracy: 0.7601 - val_loss: 0.9959\n",
      "Epoch 171/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9276 - loss: 0.1705 - val_accuracy: 0.7445 - val_loss: 0.9876\n",
      "Epoch 172/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.9197 - loss: 0.1849 - val_accuracy: 0.7488 - val_loss: 1.0043\n",
      "Epoch 173/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9258 - loss: 0.1699 - val_accuracy: 0.7573 - val_loss: 1.0205\n",
      "Epoch 174/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.9259 - loss: 0.1706 - val_accuracy: 0.7381 - val_loss: 1.0200\n",
      "Epoch 175/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9238 - loss: 0.1689 - val_accuracy: 0.7566 - val_loss: 0.9977\n",
      "Epoch 176/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9304 - loss: 0.1576 - val_accuracy: 0.7502 - val_loss: 1.0212\n",
      "Epoch 177/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9286 - loss: 0.1593 - val_accuracy: 0.7594 - val_loss: 1.0307\n",
      "Epoch 178/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.9293 - loss: 0.1632 - val_accuracy: 0.7452 - val_loss: 1.0210\n",
      "Epoch 179/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.9270 - loss: 0.1661 - val_accuracy: 0.7637 - val_loss: 1.0210\n",
      "Epoch 180/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.9297 - loss: 0.1661 - val_accuracy: 0.7594 - val_loss: 1.0304\n",
      "Epoch 181/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9248 - loss: 0.1687 - val_accuracy: 0.7594 - val_loss: 1.0436\n",
      "Epoch 182/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9341 - loss: 0.1529 - val_accuracy: 0.7480 - val_loss: 1.0474\n",
      "Epoch 183/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.9267 - loss: 0.1693 - val_accuracy: 0.7608 - val_loss: 1.0308\n",
      "Epoch 184/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9274 - loss: 0.1656 - val_accuracy: 0.7516 - val_loss: 1.0683\n",
      "Epoch 185/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9176 - loss: 0.1838 - val_accuracy: 0.7459 - val_loss: 1.0434\n",
      "Epoch 186/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.9342 - loss: 0.1587 - val_accuracy: 0.7353 - val_loss: 1.0605\n",
      "Epoch 187/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.9290 - loss: 0.1655 - val_accuracy: 0.7651 - val_loss: 1.0385\n",
      "Epoch 188/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9287 - loss: 0.1513 - val_accuracy: 0.7700 - val_loss: 1.0623\n",
      "Epoch 189/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.9278 - loss: 0.1616 - val_accuracy: 0.7601 - val_loss: 1.0674\n",
      "Epoch 190/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.9299 - loss: 0.1658 - val_accuracy: 0.7544 - val_loss: 1.0617\n",
      "Epoch 191/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.9294 - loss: 0.1606 - val_accuracy: 0.7516 - val_loss: 1.0612\n",
      "Epoch 192/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.9241 - loss: 0.1676 - val_accuracy: 0.7580 - val_loss: 1.0559\n",
      "Epoch 193/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9299 - loss: 0.1530 - val_accuracy: 0.7559 - val_loss: 1.1092\n",
      "Epoch 194/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9270 - loss: 0.1549 - val_accuracy: 0.7459 - val_loss: 1.0726\n",
      "Epoch 195/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9286 - loss: 0.1609 - val_accuracy: 0.7544 - val_loss: 1.1164\n",
      "Epoch 196/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.9301 - loss: 0.1609 - val_accuracy: 0.7395 - val_loss: 1.0774\n",
      "Epoch 197/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.9308 - loss: 0.1570 - val_accuracy: 0.7544 - val_loss: 1.0807\n",
      "Epoch 198/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.9175 - loss: 0.1844 - val_accuracy: 0.7615 - val_loss: 1.0846\n",
      "Epoch 199/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9252 - loss: 0.1627 - val_accuracy: 0.7587 - val_loss: 1.0903\n",
      "Epoch 200/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.9301 - loss: 0.1525 - val_accuracy: 0.7559 - val_loss: 1.0861\n",
      "Epoch 201/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.9225 - loss: 0.1665 - val_accuracy: 0.7473 - val_loss: 1.0769\n",
      "Epoch 202/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9292 - loss: 0.1581 - val_accuracy: 0.7431 - val_loss: 1.0954\n",
      "Epoch 203/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9280 - loss: 0.1596 - val_accuracy: 0.7573 - val_loss: 1.1088\n",
      "Epoch 204/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9339 - loss: 0.1603 - val_accuracy: 0.7452 - val_loss: 1.0942\n",
      "Epoch 205/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9339 - loss: 0.1535 - val_accuracy: 0.7637 - val_loss: 1.1086\n",
      "Epoch 206/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.9302 - loss: 0.1567 - val_accuracy: 0.7509 - val_loss: 1.1136\n",
      "Epoch 207/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.9256 - loss: 0.1558 - val_accuracy: 0.7523 - val_loss: 1.1125\n",
      "Epoch 208/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9284 - loss: 0.1563 - val_accuracy: 0.7551 - val_loss: 1.0988\n",
      "Epoch 209/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9335 - loss: 0.1468 - val_accuracy: 0.7424 - val_loss: 1.1340\n",
      "Epoch 210/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.9325 - loss: 0.1546 - val_accuracy: 0.7480 - val_loss: 1.1043\n",
      "Epoch 211/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.9248 - loss: 0.1581 - val_accuracy: 0.7530 - val_loss: 1.1164\n",
      "Epoch 212/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9299 - loss: 0.1516 - val_accuracy: 0.7417 - val_loss: 1.1157\n",
      "Epoch 213/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9254 - loss: 0.1626 - val_accuracy: 0.7594 - val_loss: 1.1186\n",
      "Epoch 214/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.9249 - loss: 0.1637 - val_accuracy: 0.7502 - val_loss: 1.1635\n",
      "Epoch 215/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9324 - loss: 0.1504 - val_accuracy: 0.7637 - val_loss: 1.1425\n",
      "Epoch 216/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.9361 - loss: 0.1505 - val_accuracy: 0.7630 - val_loss: 1.0822\n",
      "Epoch 217/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9224 - loss: 0.1828 - val_accuracy: 0.7516 - val_loss: 1.1294\n",
      "Epoch 218/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9255 - loss: 0.1654 - val_accuracy: 0.7537 - val_loss: 1.1663\n",
      "Epoch 219/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9343 - loss: 0.1518 - val_accuracy: 0.7523 - val_loss: 1.1400\n",
      "Epoch 220/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9257 - loss: 0.1736 - val_accuracy: 0.7473 - val_loss: 1.1102\n",
      "Epoch 221/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.9226 - loss: 0.1700 - val_accuracy: 0.7466 - val_loss: 1.1365\n",
      "Epoch 222/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.9219 - loss: 0.1714 - val_accuracy: 0.7537 - val_loss: 1.1278\n",
      "Epoch 223/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.9329 - loss: 0.1471 - val_accuracy: 0.7509 - val_loss: 1.1559\n",
      "Epoch 224/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.9290 - loss: 0.1605 - val_accuracy: 0.7559 - val_loss: 1.1234\n",
      "Epoch 225/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9296 - loss: 0.1582 - val_accuracy: 0.7637 - val_loss: 1.1233\n",
      "Epoch 226/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9363 - loss: 0.1529 - val_accuracy: 0.7459 - val_loss: 1.1343\n",
      "Epoch 227/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.9343 - loss: 0.1495 - val_accuracy: 0.7410 - val_loss: 1.1420\n",
      "Epoch 228/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9406 - loss: 0.1445 - val_accuracy: 0.7587 - val_loss: 1.1591\n",
      "Epoch 229/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.9199 - loss: 0.1612 - val_accuracy: 0.7573 - val_loss: 1.1512\n",
      "Epoch 230/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.9336 - loss: 0.1537 - val_accuracy: 0.7764 - val_loss: 1.1138\n",
      "Epoch 231/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9351 - loss: 0.1474 - val_accuracy: 0.7644 - val_loss: 1.1515\n",
      "Epoch 232/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9377 - loss: 0.1488 - val_accuracy: 0.7637 - val_loss: 1.1537\n",
      "Epoch 233/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9388 - loss: 0.1379 - val_accuracy: 0.7637 - val_loss: 1.1437\n",
      "Epoch 234/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.9339 - loss: 0.1444 - val_accuracy: 0.7495 - val_loss: 1.1453\n",
      "Epoch 235/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.9275 - loss: 0.1644 - val_accuracy: 0.7573 - val_loss: 1.1499\n",
      "Epoch 236/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9227 - loss: 0.1607 - val_accuracy: 0.7573 - val_loss: 1.1668\n",
      "Epoch 237/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.9202 - loss: 0.1672 - val_accuracy: 0.7544 - val_loss: 1.1858\n",
      "Epoch 238/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9293 - loss: 0.1613 - val_accuracy: 0.7665 - val_loss: 1.1307\n",
      "Epoch 239/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.9305 - loss: 0.1573 - val_accuracy: 0.7672 - val_loss: 1.2001\n",
      "Epoch 240/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9269 - loss: 0.1612 - val_accuracy: 0.7665 - val_loss: 1.1594\n",
      "Epoch 241/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.9343 - loss: 0.1490 - val_accuracy: 0.7566 - val_loss: 1.1783\n",
      "Epoch 242/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9344 - loss: 0.1483 - val_accuracy: 0.7608 - val_loss: 1.1922\n",
      "Epoch 243/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.9322 - loss: 0.1439 - val_accuracy: 0.7537 - val_loss: 1.1499\n",
      "Epoch 244/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9332 - loss: 0.1419 - val_accuracy: 0.7580 - val_loss: 1.1768\n",
      "Epoch 245/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.9284 - loss: 0.1640 - val_accuracy: 0.7523 - val_loss: 1.1946\n",
      "Epoch 246/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.9377 - loss: 0.1396 - val_accuracy: 0.7615 - val_loss: 1.1636\n",
      "Epoch 247/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9341 - loss: 0.1459 - val_accuracy: 0.7488 - val_loss: 1.1791\n",
      "Epoch 248/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.9314 - loss: 0.1497 - val_accuracy: 0.7658 - val_loss: 1.2028\n",
      "Epoch 249/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9362 - loss: 0.1513 - val_accuracy: 0.7672 - val_loss: 1.1897\n",
      "Epoch 250/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9312 - loss: 0.1520 - val_accuracy: 0.7587 - val_loss: 1.2189\n",
      "Epoch 251/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9289 - loss: 0.1520 - val_accuracy: 0.7587 - val_loss: 1.1965\n",
      "Epoch 252/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.9256 - loss: 0.1589 - val_accuracy: 0.7544 - val_loss: 1.1749\n",
      "Epoch 253/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.9383 - loss: 0.1410 - val_accuracy: 0.7601 - val_loss: 1.2109\n",
      "Epoch 254/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.9202 - loss: 0.1758 - val_accuracy: 0.7608 - val_loss: 1.1811\n",
      "Epoch 255/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.9356 - loss: 0.1416 - val_accuracy: 0.7679 - val_loss: 1.1875\n",
      "Epoch 256/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9252 - loss: 0.1611 - val_accuracy: 0.7445 - val_loss: 1.2210\n",
      "Epoch 257/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9314 - loss: 0.1478 - val_accuracy: 0.7559 - val_loss: 1.2151\n",
      "Epoch 258/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.9360 - loss: 0.1470 - val_accuracy: 0.7488 - val_loss: 1.2213\n",
      "Epoch 259/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.9309 - loss: 0.1520 - val_accuracy: 0.7551 - val_loss: 1.2086\n",
      "Epoch 260/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.9349 - loss: 0.1483 - val_accuracy: 0.7523 - val_loss: 1.2105\n",
      "Epoch 261/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9366 - loss: 0.1466 - val_accuracy: 0.7622 - val_loss: 1.2069\n",
      "Epoch 262/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9322 - loss: 0.1446 - val_accuracy: 0.7473 - val_loss: 1.2437\n",
      "Epoch 263/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9252 - loss: 0.1561 - val_accuracy: 0.7630 - val_loss: 1.2064\n",
      "Epoch 264/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9341 - loss: 0.1490 - val_accuracy: 0.7672 - val_loss: 1.1998\n",
      "Epoch 265/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9357 - loss: 0.1516 - val_accuracy: 0.7608 - val_loss: 1.2182\n",
      "Epoch 266/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.9336 - loss: 0.1528 - val_accuracy: 0.7452 - val_loss: 1.2405\n",
      "Epoch 267/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.9374 - loss: 0.1396 - val_accuracy: 0.7516 - val_loss: 1.2490\n",
      "Epoch 268/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9307 - loss: 0.1502 - val_accuracy: 0.7530 - val_loss: 1.2414\n",
      "Epoch 269/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9221 - loss: 0.1849 - val_accuracy: 0.7594 - val_loss: 1.2425\n",
      "Epoch 270/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9426 - loss: 0.1345 - val_accuracy: 0.7715 - val_loss: 1.2188\n",
      "Epoch 271/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.9347 - loss: 0.1457 - val_accuracy: 0.7708 - val_loss: 1.2223\n",
      "Epoch 272/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9336 - loss: 0.1496 - val_accuracy: 0.7544 - val_loss: 1.2414\n",
      "Epoch 273/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9430 - loss: 0.1388 - val_accuracy: 0.7644 - val_loss: 1.2487\n",
      "Epoch 274/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.9380 - loss: 0.1423 - val_accuracy: 0.7587 - val_loss: 1.2764\n",
      "Epoch 275/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9390 - loss: 0.1402 - val_accuracy: 0.7708 - val_loss: 1.2151\n",
      "Epoch 276/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9367 - loss: 0.1413 - val_accuracy: 0.7644 - val_loss: 1.2561\n",
      "Epoch 277/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9415 - loss: 0.1385 - val_accuracy: 0.7502 - val_loss: 1.2577\n",
      "Epoch 278/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.9343 - loss: 0.1422 - val_accuracy: 0.7601 - val_loss: 1.2744\n",
      "Epoch 279/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9367 - loss: 0.1414 - val_accuracy: 0.7637 - val_loss: 1.2567\n",
      "Epoch 280/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.9304 - loss: 0.1553 - val_accuracy: 0.7622 - val_loss: 1.2963\n",
      "Epoch 281/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9396 - loss: 0.1386 - val_accuracy: 0.7431 - val_loss: 1.3328\n",
      "Epoch 282/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9364 - loss: 0.1391 - val_accuracy: 0.7708 - val_loss: 1.2718\n",
      "Epoch 283/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.9308 - loss: 0.1466 - val_accuracy: 0.7566 - val_loss: 1.2692\n",
      "Epoch 284/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9327 - loss: 0.1536 - val_accuracy: 0.7502 - val_loss: 1.2704\n",
      "Epoch 285/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.9314 - loss: 0.1506 - val_accuracy: 0.7630 - val_loss: 1.2632\n",
      "Epoch 286/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9355 - loss: 0.1519 - val_accuracy: 0.7580 - val_loss: 1.2728\n",
      "Epoch 287/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9336 - loss: 0.1513 - val_accuracy: 0.7566 - val_loss: 1.2750\n",
      "Epoch 288/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.9410 - loss: 0.1357 - val_accuracy: 0.7431 - val_loss: 1.2645\n",
      "Epoch 289/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.9378 - loss: 0.1456 - val_accuracy: 0.7516 - val_loss: 1.2838\n",
      "Epoch 290/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.9368 - loss: 0.1404 - val_accuracy: 0.7644 - val_loss: 1.2495\n",
      "Epoch 291/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.9382 - loss: 0.1434 - val_accuracy: 0.7580 - val_loss: 1.2757\n",
      "Epoch 292/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9314 - loss: 0.1456 - val_accuracy: 0.7622 - val_loss: 1.2445\n",
      "Epoch 293/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9367 - loss: 0.1395 - val_accuracy: 0.7459 - val_loss: 1.3328\n",
      "Epoch 294/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.9343 - loss: 0.1492 - val_accuracy: 0.7587 - val_loss: 1.2946\n",
      "Epoch 295/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.9385 - loss: 0.1379 - val_accuracy: 0.7495 - val_loss: 1.3138\n",
      "Epoch 296/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.9389 - loss: 0.1399 - val_accuracy: 0.7495 - val_loss: 1.3036\n",
      "Epoch 297/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9347 - loss: 0.1516 - val_accuracy: 0.7608 - val_loss: 1.3182\n",
      "Epoch 298/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9323 - loss: 0.1489 - val_accuracy: 0.7573 - val_loss: 1.2918\n",
      "Epoch 299/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.9451 - loss: 0.1320 - val_accuracy: 0.7544 - val_loss: 1.2993\n",
      "Epoch 300/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.9246 - loss: 0.1605 - val_accuracy: 0.7473 - val_loss: 1.3555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3120e8bd0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=300, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80477b49-0341-4e58-89fc-944a9b7700bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4799344 , 0.6762104 ],\n",
       "       [0.47484723, 0.64561516],\n",
       "       [0.48325592, 0.67417765],\n",
       "       ...,\n",
       "       [0.48351115, 0.6634803 ],\n",
       "       [0.45274124, 0.65285677],\n",
       "       [0.47008267, 0.6781703 ]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "32769990-4a9c-4978-affb-e4d0a30c2f06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b3730480-7c62-43a7-8205-33c92c85f030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:, 0]>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "25663e73-6ae5-4a8a-9e0c-b24e36f4c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "685ceb1d-5da9-4d5a-8fcd-df42044ba81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[879, 157],\n",
       "       [184, 189]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the probabilities to binary class predictions (0 or 1)\n",
    "y_pred_class = y_pred.argmax(axis=1)  # Takes the class with the highest probability (0 or 1)\n",
    "\n",
    "# Now you can generate and display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d14bcd93-7097-4f87-a9e9-9e58e8e82a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "08286484-5f13-469b-b265-6a8468fb581a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185     1\n",
       "2715    0\n",
       "3825    0\n",
       "1807    1\n",
       "132     0\n",
       "       ..\n",
       "6366    0\n",
       "315     0\n",
       "2439    0\n",
       "5002    0\n",
       "1161    1\n",
       "Name: Churn, Length: 1409, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad219cd-8114-4ce8-8df8-d18abe7e0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f940af33-427e-401a-9318-4177ddb6b12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7636 - loss: 0.5239\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9f7da8d-b54c-49e8-9cdd-a56cbce77b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7693399786949158"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1398587-cee5-4e68-8b6c-56168cc724d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4173444228.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    ,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             InputLayer(input_shape = (8,)),\n",
    "                             ,\n",
    "                             Dense(128, activation = \"relu\"),\n",
    "                             Dense(128, activation = \"relu\"),\n",
    "                             Dense(128, activation = \"relu\"),\n",
    "                             Dense(2,activation = 'sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777f7de-82c0-4dab-8953-646896b03a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
